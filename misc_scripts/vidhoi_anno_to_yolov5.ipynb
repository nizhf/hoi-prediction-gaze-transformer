{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate VidOR annotations for YOLOv5 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from typing import List\n",
    "\n",
    "dataset_path = Path(\"/mnt/DATA/datasets/VidOR/\")\n",
    "training_annotation_path = dataset_path / \"annotation\" / \"training\"\n",
    "validation_annotation_path = dataset_path / \"annotation\" / \"validation\"\n",
    "training_annotation_files = list(training_annotation_path.glob(\"*/*.json\"))\n",
    "validation_annotation_files = list(validation_annotation_path.glob(\"*/*.json\"))\n",
    "annotation_files = training_annotation_files + validation_annotation_files\n",
    "print(len(training_annotation_files))\n",
    "print(len(validation_annotation_files))\n",
    "anno_file = training_annotation_files[1551]\n",
    "print(anno_file)\n",
    "with anno_file.open(\"r\") as f:\n",
    "    anno_json = json.load(f)\n",
    "\n",
    "print(anno_json.keys())\n",
    "print(len(anno_json[\"subject/objects\"]))\n",
    "print(len(anno_json[\"trajectories\"]))\n",
    "print(anno_json[\"frame_count\"])\n",
    "for item in anno_json[\"subject/objects\"]:\n",
    "    print(item[\"category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_classes = [\"adult\", \"child\", \"baby\"]\n",
    "object_classes = [\n",
    "    \"person\",\n",
    "    \"car\",\n",
    "    \"guitar\",\n",
    "    \"chair\",\n",
    "    \"handbag\",\n",
    "    \"toy\",\n",
    "    \"baby_seat\",\n",
    "    \"cat\",\n",
    "    \"bottle\",\n",
    "    \"backpack\",\n",
    "    \"motorcycle\",\n",
    "    \"ball/sports_ball\",\n",
    "    \"laptop\",\n",
    "    \"table\",\n",
    "    \"surfboard\",\n",
    "    \"camera\",\n",
    "    \"sofa\",\n",
    "    \"screen/monitor\",\n",
    "    \"bicycle\",\n",
    "    \"vegetables\",\n",
    "    \"dog\",\n",
    "    \"fruits\",\n",
    "    \"cake\",\n",
    "    \"cellphone\",\n",
    "    \"cup\",\n",
    "    \"bench\",\n",
    "    \"snowboard\",\n",
    "    \"skateboard\",\n",
    "    \"bread\",\n",
    "    \"bus/truck\",\n",
    "    \"ski\",\n",
    "    \"suitcase\",\n",
    "    \"stool\",\n",
    "    \"bat\",\n",
    "    \"elephant\",\n",
    "    \"fish\",\n",
    "    \"baby_walker\",\n",
    "    \"dish\",\n",
    "    \"watercraft\",\n",
    "    \"scooter\",\n",
    "    \"pig\",\n",
    "    \"refrigerator\",\n",
    "    \"horse\",\n",
    "    \"crab\",\n",
    "    \"bird\",\n",
    "    \"piano\",\n",
    "    \"cattle/cow\",\n",
    "    \"lion\",\n",
    "    \"chicken\",\n",
    "    \"camel\",\n",
    "    \"electric_fan\",\n",
    "    \"toilet\",\n",
    "    \"sheep/goat\",\n",
    "    \"rabbit\",\n",
    "    \"train\",\n",
    "    \"penguin\",\n",
    "    \"hamster/rat\",\n",
    "    \"snake\",\n",
    "    \"frisbee\",\n",
    "    \"aircraft\",\n",
    "    \"oven\",\n",
    "    \"racket\",\n",
    "    \"faucet\",\n",
    "    \"antelope\",\n",
    "    \"duck\",\n",
    "    \"stop_sign\",\n",
    "    \"sink\",\n",
    "    \"kangaroo\",\n",
    "    \"stingray\",\n",
    "    \"turtle\",\n",
    "    \"tiger\",\n",
    "    \"crocodile\",\n",
    "    \"bear\",\n",
    "    \"microwave\",\n",
    "    \"traffic_light\",\n",
    "    \"panda\",\n",
    "    \"leopard\",\n",
    "    \"squirrel\",\n",
    "]\n",
    "name_to_idx = {name: idx for idx, name in enumerate(object_classes)}\n",
    "for name in human_classes:\n",
    "    name_to_idx[name] = 0\n",
    "print(name_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_count = {object_class: 0 for object_class in object_classes}\n",
    "unknown_count = {}\n",
    "generated_trace_count = 0\n",
    "total_trace_count = 0\n",
    "empty_frame_count = 0\n",
    "manually_frame_count = 0\n",
    "total_frame_count = 0\n",
    "\n",
    "for anno_file in tqdm(annotation_files):\n",
    "    with anno_file.open(\"r\") as f:\n",
    "        anno_txt = f.read()\n",
    "        anno_json = json.loads(anno_txt)\n",
    "    for item in anno_json[\"subject/objects\"]:\n",
    "        subject = item[\"category\"]\n",
    "        if subject in human_classes:\n",
    "            object_count[\"person\"] += 1\n",
    "        elif subject in object_classes:\n",
    "            object_count[subject] += 1\n",
    "        elif subject in unknown_count.keys():\n",
    "            unknown_count[subject] += 1\n",
    "        else:\n",
    "            unknown_count[subject] = 1\n",
    "    for frame_item in anno_json[\"trajectories\"]:\n",
    "        total_frame_count += 1\n",
    "        if len(frame_item) > 0:\n",
    "            frame_has_manually = False\n",
    "            for trajectories in frame_item:\n",
    "                if trajectories[\"generated\"] == 1:\n",
    "                    generated_trace_count += 1\n",
    "                else:\n",
    "                    frame_has_manually = True\n",
    "                total_trace_count += 1\n",
    "            manually_frame_count += int(frame_has_manually)\n",
    "        else:\n",
    "            empty_frame_count += 1\n",
    "\n",
    "\n",
    "print(object_count)\n",
    "print(unknown_count)\n",
    "print(f\"Totally {total_frame_count} frames\")\n",
    "print(f\"Totally {total_trace_count} traces\")\n",
    "print(f\"Empty rate: {empty_frame_count / total_frame_count * 100:.2f}%\")\n",
    "print(\n",
    "    f\"Generated rate trace rate: {generated_trace_count / total_trace_count * 100:.2f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Frames with at least one manually annotated bbox: {manually_frame_count / total_frame_count * 100:.2f}%\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_yolov5_annotation_interval(\n",
    "    annotation_files: List[Path], output_path: Path, trace_interval\n",
    "):\n",
    "    image_filename_list = []\n",
    "    for anno_file in tqdm(annotation_files):\n",
    "        with anno_file.open(\"r\") as f:\n",
    "            anno_json = json.load(f)\n",
    "        width = anno_json[\"width\"]\n",
    "        height = anno_json[\"height\"]\n",
    "        id_to_label = [\n",
    "            name_to_idx[obj[\"category\"]] for obj in anno_json[\"subject/objects\"]\n",
    "        ]\n",
    "\n",
    "        video_path = Path(anno_json[\"video_path\"]).parent\n",
    "        video_id = anno_json[\"video_id\"]\n",
    "        yolo_anno_path: Path = output_path / video_path / video_id\n",
    "        if not yolo_anno_path.exists():\n",
    "            yolo_anno_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for frame_num, traces in enumerate(anno_json[\"trajectories\"][::trace_interval]):\n",
    "            yolo_anno_file = (\n",
    "                yolo_anno_path / f\"{video_id}_{frame_num * trace_interval + 1:06d}.txt\"\n",
    "            )\n",
    "            yolo_anno_str = \"\"\n",
    "            if len(traces) > 0:\n",
    "                for trace in traces:\n",
    "                    label = id_to_label[trace[\"tid\"]]\n",
    "                    bbox = trace[\"bbox\"]\n",
    "                    bbox_width = (bbox[\"xmax\"] - bbox[\"xmin\"]) / width\n",
    "                    bbox_height = (bbox[\"ymax\"] - bbox[\"ymin\"]) / height\n",
    "                    x_center = ((bbox[\"xmax\"] + bbox[\"xmin\"]) / 2) / width\n",
    "                    y_center = ((bbox[\"ymax\"] + bbox[\"ymin\"]) / 2) / height\n",
    "                    yolo_anno_str += (\n",
    "                        f\"{label} {x_center} {y_center} {bbox_width} {bbox_height}\\n\"\n",
    "                    )\n",
    "\n",
    "            with yolo_anno_file.open(\"w\") as f:\n",
    "                f.write(yolo_anno_str)\n",
    "            label_filename = yolo_anno_file.as_posix()\n",
    "            image_filename_list.append(\n",
    "                label_filename.replace(\"labels\", \"images\").replace(\"txt\", \"jpg\") + \"\\n\"\n",
    "            )\n",
    "    return image_filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_yolov5_annotation_manually_only(\n",
    "    annotation_files: List[Path], output_path: Path\n",
    "):\n",
    "    image_filename_list = []\n",
    "    for anno_file in tqdm(annotation_files):\n",
    "        with anno_file.open(\"r\") as f:\n",
    "            anno_json = json.load(f)\n",
    "        width = anno_json[\"width\"]\n",
    "        height = anno_json[\"height\"]\n",
    "        id_to_label = [\n",
    "            name_to_idx[obj[\"category\"]] for obj in anno_json[\"subject/objects\"]\n",
    "        ]\n",
    "\n",
    "        video_path = Path(anno_json[\"video_path\"]).parent\n",
    "        video_id = anno_json[\"video_id\"]\n",
    "        yolo_anno_path: Path = output_path / video_path / video_id\n",
    "        if not yolo_anno_path.exists():\n",
    "            yolo_anno_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for frame_num, traces in enumerate(anno_json[\"trajectories\"]):\n",
    "            yolo_anno_file = yolo_anno_path / f\"{video_id}_{frame_num + 1:06d}.txt\"\n",
    "            yolo_anno_str = \"\"\n",
    "            frame_manually = True\n",
    "            if len(traces) > 0:\n",
    "                for trace in traces:\n",
    "                    if trace[\"generated\"] == 1:\n",
    "                        frame_manually = False\n",
    "                        break\n",
    "                    label = id_to_label[trace[\"tid\"]]\n",
    "                    bbox = trace[\"bbox\"]\n",
    "                    bbox_width = (bbox[\"xmax\"] - bbox[\"xmin\"]) / width\n",
    "                    bbox_height = (bbox[\"ymax\"] - bbox[\"ymin\"]) / height\n",
    "                    x_center = ((bbox[\"xmax\"] + bbox[\"xmin\"]) / 2) / width\n",
    "                    y_center = ((bbox[\"ymax\"] + bbox[\"ymin\"]) / 2) / height\n",
    "                    yolo_anno_str += (\n",
    "                        f\"{label} {x_center} {y_center} {bbox_width} {bbox_height}\\n\"\n",
    "                    )\n",
    "            # add some empty frames\n",
    "            # if frame_manually or (len(traces) == 0 and frame_num // 15 == 0):\n",
    "            if frame_manually and len(traces) > 0:\n",
    "                with yolo_anno_file.open(\"w\") as f:\n",
    "                    f.write(yolo_anno_str)\n",
    "                label_filename = yolo_anno_file.as_posix()\n",
    "                image_filename_list.append(\n",
    "                    label_filename.replace(\"labels\", \"images\").replace(\"txt\", \"jpg\")\n",
    "                    + \"\\n\"\n",
    "                )\n",
    "\n",
    "    return image_filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_yolov5_annotation_vidhoi_only(\n",
    "    dataset_path: Path, output_path: Path, train=True,\n",
    "):\n",
    "    annotation_path = dataset_path / \"annotation\"\n",
    "    if train:\n",
    "        vidhoi_annotation_path = dataset_path / \"VidHOI_annotation\" / \"train_frame_annots.json\"\n",
    "        annotation_path = annotation_path / \"training\"\n",
    "    else:\n",
    "        vidhoi_annotation_path = dataset_path / \"VidHOI_annotation\" / \"val_frame_annots.json\"\n",
    "        annotation_path = annotation_path / \"validation\"\n",
    "\n",
    "    with vidhoi_annotation_path.open() as f:\n",
    "        vidhoi_annotation_json = json.load(f)\n",
    "\n",
    "    image_filename_list = []\n",
    "    last_video_id = \"\"\n",
    "    last_frame_id = \"\"\n",
    "    for entry in tqdm(vidhoi_annotation_json):\n",
    "        video_path = entry[\"video_folder\"]\n",
    "        video_id = entry[\"video_id\"]        \n",
    "        yolo_anno_path: Path = output_path / video_path / video_id\n",
    "        if not yolo_anno_path.exists():\n",
    "            yolo_anno_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        frame_id = entry[\"frame_id\"]\n",
    "        frame_num = int(frame_id) - 1\n",
    "        if video_id == last_video_id and frame_id == last_frame_id:\n",
    "            continue\n",
    "        \n",
    "        last_video_id = video_id\n",
    "        last_frame_id = frame_id\n",
    "\n",
    "        anno_file = annotation_path / video_path / f\"{video_id}.json\"\n",
    "        with anno_file.open(\"r\") as f:\n",
    "            anno_json = json.load(f)\n",
    "        width = anno_json[\"width\"]\n",
    "        height = anno_json[\"height\"]\n",
    "        id_to_label = [\n",
    "            name_to_idx[obj[\"category\"]] for obj in anno_json[\"subject/objects\"]\n",
    "        ]\n",
    "        yolo_anno_file = yolo_anno_path / f\"{video_id}_{frame_num + 1:06d}.txt\"\n",
    "        yolo_anno_str = \"\"\n",
    "        traces = anno_json[\"trajectories\"][frame_num]\n",
    "        if len(traces) > 0:\n",
    "            for trace in traces:\n",
    "                label = id_to_label[trace[\"tid\"]]\n",
    "                bbox = trace[\"bbox\"]\n",
    "                bbox_width = (bbox[\"xmax\"] - bbox[\"xmin\"]) / width\n",
    "                bbox_height = (bbox[\"ymax\"] - bbox[\"ymin\"]) / height\n",
    "                x_center = ((bbox[\"xmax\"] + bbox[\"xmin\"]) / 2) / width\n",
    "                y_center = ((bbox[\"ymax\"] + bbox[\"ymin\"]) / 2) / height\n",
    "                yolo_anno_str += (\n",
    "                    f\"{label} {x_center} {y_center} {bbox_width} {bbox_height}\\n\"\n",
    "                )\n",
    "            with yolo_anno_file.open(\"w\") as f:\n",
    "                f.write(yolo_anno_str)\n",
    "            label_filename = yolo_anno_file.as_posix()\n",
    "            image_filename_list.append(\n",
    "                label_filename.replace(\"labels\", \"images\").replace(\"txt\", \"jpg\")\n",
    "                + \"\\n\"\n",
    "            )\n",
    "\n",
    "    return image_filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Generating labels with interval 30...\")\n",
    "# output_path = dataset_path / \"labels\"\n",
    "# # annotation_files_sorted = sorted(annotation_files, key=lambda x: str(x))\n",
    "# image_filename_list = generate_yolov5_annotation_interval(\n",
    "#     training_annotation_files, output_path, 30\n",
    "# )\n",
    "# print(f\"Training: {len(image_filename_list)} frames\")\n",
    "# training_image_txt = dataset_path / \"yolov5_train.txt\"\n",
    "# with training_image_txt.open(\"w\") as f:\n",
    "#     f.writelines(image_filename_list)\n",
    "\n",
    "# image_filename_list = generate_yolov5_annotation_interval(\n",
    "#     validation_annotation_files, output_path, 30\n",
    "# )\n",
    "# print(f\"Validation: {len(image_filename_list)} frames\")\n",
    "# val_image_txt = dataset_path / \"yolov5_val.txt\"\n",
    "# with val_image_txt.open(\"w\") as f:\n",
    "#     f.writelines(image_filename_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating labels with only manually labeled frames...\")\n",
    "output_path = dataset_path / \"labels\"\n",
    "# annotation_files_sorted = sorted(annotation_files, key=lambda x: str(x))\n",
    "image_filename_list = generate_yolov5_annotation_manually_only(\n",
    "    training_annotation_files, output_path\n",
    ")\n",
    "print(f\"Training: {len(image_filename_list)} frames\")\n",
    "training_image_txt = dataset_path / \"yolov5_train_manually.txt\"\n",
    "with training_image_txt.open(\"w\") as f:\n",
    "    f.writelines(image_filename_list)\n",
    "\n",
    "image_filename_list = generate_yolov5_annotation_manually_only(\n",
    "    validation_annotation_files, output_path\n",
    ")\n",
    "print(f\"Validation: {len(image_filename_list)} frames\")\n",
    "val_image_txt = dataset_path / \"yolov5_val_manually.txt\"\n",
    "with val_image_txt.open(\"w\") as f:\n",
    "    f.writelines(image_filename_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Generating labels with only vidhoi frames...\")\n",
    "# output_path = dataset_path / \"labels\"\n",
    "# # annotation_files_sorted = sorted(annotation_files, key=lambda x: str(x))\n",
    "# image_filename_list = generate_yolov5_annotation_vidhoi_only(\n",
    "#     dataset_path, output_path, True\n",
    "# )\n",
    "# print(f\"Training: {len(image_filename_list)} frames\")\n",
    "# training_image_txt = dataset_path / \"yolov5_train_vidhoi.txt\"\n",
    "# with training_image_txt.open(\"w\") as f:\n",
    "#     f.writelines(image_filename_list)\n",
    "\n",
    "# image_filename_list = generate_yolov5_annotation_vidhoi_only(\n",
    "#     dataset_path, output_path, False\n",
    "# )\n",
    "# print(f\"Validation: {len(image_filename_list)} frames\")\n",
    "# val_image_txt = dataset_path / \"yolov5_val_vidhoi.txt\"\n",
    "# with val_image_txt.open(\"w\") as f:\n",
    "#     f.writelines(image_filename_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hoi_torch110')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10be537dd544c2db9f613ac2c2c3348a8740d82fea605a7c3e8129db29e3148b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
